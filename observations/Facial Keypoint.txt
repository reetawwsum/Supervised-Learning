training.csv is so big, opening it directly makes my workstation slow.
Instead of one real value target in regression problem, this particular problem has 30 of them.
Problem is whether these targets are inter-dependent.
Length of training dataset is 7049. Hence, initially working on 5 percent of training dataset.

Observations on dataset:
1. Two images with missing keypoint located in 5 percent dataset. It appears that it is missing because keypoint is out of the picture. For now, I'm using mean value to fill them, but by plotting them, I can see a better solution.
2. Just filling the one axis as extreme end and other same as that of it's opposite keypoint, I can fill the missing keypoint optimally. For e.g if mouth_center_bottom_lip_x and mouth_center_bottom_lip_y are missing, then mouth_center_bottom_lip_x = mouth_center_top_lip_x and mouth_center_bottom_lip_y = max(y)
3. But, since missing values are very less. For now, I'm implementing the mean value idea. 
4. Since, number of features is greater than number of samples, I'm gonna use SVR with linear kernel.
5. After fitting my model on 15 percent datast, it appears SVR with hyperparameters found by using GridSearchCV is saturating at 70 percent.
6. My program took 1 hour, but still unable to process all of training.csv file in order to train my SVM model.
7. Either I have to go for parallel processing, or I should change my model.